{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "TozeeGcEgfO0",
        "erGHdgJUgfPH",
        "HVDhUiMmgfPZ"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CMWENLIU/Drug_label_embedding/blob/master/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR7AjTKxglcd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "594e0887-76f0-43a0-b061-c2603efd55ee"
      },
      "source": [
        "! pip install --quiet word2vec\n",
        "! pip install --quiet wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDQ5YSwk-gMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wget\n",
        "import word2vec\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3azPI5vagfKL",
        "colab_type": "text"
      },
      "source": [
        "# word2vec "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch1oi9SDgfKW",
        "colab_type": "text"
      },
      "source": [
        "This notebook is equivalent to `demo-word.sh`, `demo-analogy.sh`, `demo-phrases.sh` and `demo-classes.sh` from Google."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r23HX4sKgfKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ccab5d8b-ccea-488a-d3ce-9b4ffe769cf6"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "urls = [\"https://raw.githubusercontent.com/CMWENLIU/Drug_label_embedding/master/pubmed/abs1.txt\",\n",
        "       \"https://raw.githubusercontent.com/CMWENLIU/Drug_label_embedding/master/pubmed/abs2.txt\",\n",
        "       ]\n",
        "[wget.download(u) for u in urls]   "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abs1.txt', 'abs2.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQIlfXKgjcZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_str(string):\n",
        "   \n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = string.replace(\"\\\\\",\"\")\n",
        "    return string.strip().lower()\n",
        "\n",
        "def split_record(s):\n",
        "  journal = s.split('-!!-', 1)[0]\n",
        "  temp = s.split('-!!-', 1)[1]\n",
        "  year = temp.split('-##-', 1)[0]\n",
        "  abstract = s.split('-##-', 1)[1]\n",
        "  return journal, year, abstract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs9x0KHV97cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('w2vdata', 'w') as wf:\n",
        "  with open('abs1.txt') as f:\n",
        "    for line in f:\n",
        "      line = clean_str(line)\n",
        "      wf.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMsyiyECgfKn",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Pw6toxgfK4",
        "colab_type": "text"
      },
      "source": [
        "Run `word2phrase` to group up similar words \"Los Angeles\" to \"Los_Angeles\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-jLVKWzgfK6",
        "colab_type": "code",
        "outputId": "90de0b93-c62c-47dc-fb3a-620844838146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "word2vec.word2phrase('w2vdata', 'w2vdata-phrases', verbose=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training using file w2vdata\n",
            "\n",
            "Vocab size (unigrams + bigrams): 335899\n",
            "Words in train file: 1716190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK12eA7_gfLE",
        "colab_type": "text"
      },
      "source": [
        "This created a `text8-phrases` file that we can use as a better input for `word2vec`.\n",
        "Note that you could easily skip this previous step and use the text data as input for `word2vec` directly.\n",
        "\n",
        "Now actually train the word2vec model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1JqcPAwgfLG",
        "colab_type": "code",
        "outputId": "592ba8e4-d0f5-46a8-b5b5-7389bb5d224b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "word2vec.word2vec('w2vdata-phrases', 'w2vdata.bin', size=100, verbose=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training using file w2vdata-phrases\n",
            "Vocab size: 21335\n",
            "Words in train file: 1537115\n",
            "Alpha: 0.000002  Progress: 100.20%  Words/thread/sec: 193.62k  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbDXPFk0gfLS",
        "colab_type": "text"
      },
      "source": [
        "That created a `text8.bin` file containing the word vectors in a binary format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVMhRjqjgfLa",
        "colab_type": "text"
      },
      "source": [
        "Now we generate the clusters of the vectors based on the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl0elmE1gfLc",
        "colab_type": "code",
        "outputId": "aab6efe7-5f2a-4d4b-e845-6eaf3c921559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "word2vec.word2clusters('w2vdata', 'w2vdata-clusters.txt', 100, verbose=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training using file w2vdata\n",
            "Vocab size: 17654\n",
            "Words in train file: 1652908\n",
            "Alpha: 0.000002  Progress: 100.28%  Words/thread/sec: 190.35k  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_FBKaoOgfLn",
        "colab_type": "text"
      },
      "source": [
        "That created a `text8-clusters.txt` with the cluster for every word in the vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV-GEdnAgfLq",
        "colab_type": "text"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy5jgVbIgfLt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ab748c20-554d-479a-f33c-029b4bdb0bc9"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCCdfrLZgfMH",
        "colab_type": "text"
      },
      "source": [
        "Import the `word2vec` binary file created above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h77QQF8_gfMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = word2vec.load('w2vdata.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjZB01j5gfMO",
        "colab_type": "text"
      },
      "source": [
        "We can take a look at the vocabulary as a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvWh2b0igfMR",
        "colab_type": "code",
        "outputId": "8690c2dc-6c8e-4cb5-9da1-6d64e1b4fdf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.vocab"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['</s>', 'the', ',', ..., 'sw', 'lfcs', 'usat'], dtype='<U78')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF4A-9Q0gfMi",
        "colab_type": "text"
      },
      "source": [
        "Or take a look at the whole matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA9z9gN1gfMm",
        "colab_type": "code",
        "outputId": "c8aa27ff-ea2e-40c9-da98-3497b60ea646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.vectors.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21335, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsm45nLZgfMy",
        "colab_type": "code",
        "outputId": "0e64735a-0f4e-4550-9756-5a838b9a0cfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "model.vectors"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.14333282,  0.15825513, -0.13715845, ...,  0.05456942,\n",
              "         0.10955409,  0.00693387],\n",
              "       [ 0.08136111, -0.07500461,  0.01063167, ..., -0.04574704,\n",
              "         0.0701974 , -0.12510048],\n",
              "       [-0.0591997 , -0.04052412,  0.00540176, ...,  0.13127078,\n",
              "        -0.00493684,  0.06459591],\n",
              "       ...,\n",
              "       [ 0.08967227, -0.14987729,  0.09585784, ...,  0.10959856,\n",
              "        -0.11328791, -0.01284291],\n",
              "       [-0.02349118, -0.23456866,  0.17473452, ...,  0.09311981,\n",
              "        -0.02780636, -0.01349567],\n",
              "       [ 0.00334223, -0.14207917,  0.01476534, ...,  0.13891329,\n",
              "        -0.05570399, -0.00767328]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NztBBHRbgfND",
        "colab_type": "text"
      },
      "source": [
        "We can retreive the vector of individual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9GmV3-bgfNF",
        "colab_type": "code",
        "outputId": "b6a6b4e0-b323-4d68-f559-2774be65c3d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model['dog'].shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAU4Vd3qgfNN",
        "colab_type": "code",
        "outputId": "e402412e-b322-4316-ac76-20812f46a4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model['dog'][:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.03412343, -0.21800287,  0.09563856, -0.05208769,  0.02066191,\n",
              "        0.00465136,  0.01780929,  0.01945632, -0.11154303,  0.11058243])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abCeT_w3gfNe",
        "colab_type": "text"
      },
      "source": [
        "We can calculate the distance between two or more (all combinations) words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDLt4t7hgfNn",
        "colab_type": "code",
        "outputId": "5fb9724b-a42c-48e1-8896-fe6b302e069e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.distance(\"dog\", \"cat\", \"fish\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dog', 'cat', 0.8139222866656213),\n",
              " ('dog', 'fish', 0.7836921646553869),\n",
              " ('cat', 'fish', 0.6833860218539964)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcT2BVvAgfNz",
        "colab_type": "text"
      },
      "source": [
        "## Similarity\n",
        "\n",
        "We can do simple queries to retreive words similar to \"socks\" based on cosine similarity:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7eHXaEWgfN0",
        "colab_type": "code",
        "outputId": "9d995233-253f-4a81-8cb1-712c5469682c",
        "colab": {}
      },
      "source": [
        "indexes, metrics = model.similar(\"dog\")\n",
        "indexes, metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 2437,  5478,  7593, 10230,  3964,  9963,  2428, 10309,  4812,\n",
              "         2391]),\n",
              " array([0.86937327, 0.83396105, 0.77854628, 0.7692265 , 0.76743628,\n",
              "        0.7612772 , 0.7600788 , 0.75935677, 0.75693881, 0.75438956]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8KVq_dbgfN_",
        "colab_type": "text"
      },
      "source": [
        "This returned a tuple with 2 items:\n",
        "1. numpy array with the indexes of the similar words in the vocabulary\n",
        "2. numpy array with cosine similarity to each word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9bHxJcZgfOD",
        "colab_type": "text"
      },
      "source": [
        "We can get the words for those indexes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATm-dUMLgfOF",
        "colab_type": "code",
        "outputId": "f73b25a2-c29a-4d7f-92ce-106461150969",
        "colab": {}
      },
      "source": [
        "model.vocab[indexes]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['cat', 'cow', 'goat', 'pig', 'dogs', 'rabbit', 'bear', 'rat',\n",
              "       'wolf', 'girl'], dtype='<U78')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GRWsL91gfOa",
        "colab_type": "text"
      },
      "source": [
        "There is a helper function to create a combined response as a numpy [record array](http://docs.scipy.org/doc/numpy/user/basics.rec.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CySBuJuQgfOb",
        "colab_type": "code",
        "outputId": "af22cb6c-ab7a-48fd-a6ba-dbc88ecce24c",
        "colab": {}
      },
      "source": [
        "model.generate_response(indexes, metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rec.array([('cat', 0.86937327), ('cow', 0.83396105), ('goat', 0.77854628),\n",
              "           ('pig', 0.7692265 ), ('dogs', 0.76743628),\n",
              "           ('rabbit', 0.7612772 ), ('bear', 0.7600788 ),\n",
              "           ('rat', 0.75935677), ('wolf', 0.75693881),\n",
              "           ('girl', 0.75438956)],\n",
              "          dtype=[('word', '<U78'), ('metric', '<f8')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxK8TqHIgfOl",
        "colab_type": "text"
      },
      "source": [
        "Is easy to make that numpy array a pure python response:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWyT8PujgfOr",
        "colab_type": "code",
        "outputId": "d7ee56c3-2851-42db-9faf-335a653743fe",
        "colab": {}
      },
      "source": [
        "model.generate_response(indexes, metrics).tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cat', 0.8693732680572173),\n",
              " ('cow', 0.8339610529888226),\n",
              " ('goat', 0.7785462766666428),\n",
              " ('pig', 0.7692265048531302),\n",
              " ('dogs', 0.7674362783482181),\n",
              " ('rabbit', 0.7612771996422674),\n",
              " ('bear', 0.7600788045286304),\n",
              " ('rat', 0.7593567655129181),\n",
              " ('wolf', 0.7569388070301634),\n",
              " ('girl', 0.754389556345068)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TozeeGcEgfO0",
        "colab_type": "text"
      },
      "source": [
        "### Phrases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDFRuC6PgfO2",
        "colab_type": "text"
      },
      "source": [
        "Since we trained the model with the output of `word2phrase` we can ask for similarity of \"phrases\", basically compained words such as \"Los Angeles\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuniNouigfO3",
        "colab_type": "code",
        "outputId": "34ea2627-5854-46b8-99f5-2be5204b7659",
        "colab": {}
      },
      "source": [
        "indexes, metrics = model.similar('los_angeles')\n",
        "model.generate_response(indexes, metrics).tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('san_francisco', 0.8876351265573288),\n",
              " ('san_diego', 0.8652920422732189),\n",
              " ('seattle', 0.8387625165949533),\n",
              " ('las_vegas', 0.8325965377422355),\n",
              " ('california', 0.8252775393303263),\n",
              " ('miami', 0.8167069457881345),\n",
              " ('detroit', 0.8164911899252103),\n",
              " ('chicago', 0.813283620659967),\n",
              " ('cincinnati', 0.8116379669114295),\n",
              " ('cleveland', 0.810708205429068)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erGHdgJUgfPH",
        "colab_type": "text"
      },
      "source": [
        "### Analogies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDlCYBIagfPI",
        "colab_type": "text"
      },
      "source": [
        "Its possible to do more complex queries like analogies such as: `king - man + woman = queen` \n",
        "This method returns the same as `cosine` the indexes of the words in the vocab and the metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHOGGqmSgfPJ",
        "colab_type": "code",
        "outputId": "22c4bdb8-9c9c-49ec-dc57-5c3cc4228010",
        "colab": {}
      },
      "source": [
        "indexes, metrics = model.analogy(pos=['king', 'woman'], neg=['man'])\n",
        "indexes, metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1087, 6768, 1145, 7523, 1335, 8419, 3141, 1827,  344, 4980]),\n",
              " array([0.28823424, 0.26614362, 0.26265608, 0.26111525, 0.26091172,\n",
              "        0.25844542, 0.25781944, 0.25678284, 0.25424551, 0.2529607 ]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdtmMnUdgfPO",
        "colab_type": "code",
        "outputId": "d43ed858-dba9-40f3-ab4e-b78dfc251b22",
        "colab": {}
      },
      "source": [
        "model.generate_response(indexes, metrics).tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.28823424120681784),\n",
              " ('regent', 0.26614361576778933),\n",
              " ('prince', 0.2626560787162791),\n",
              " ('empress', 0.2611152451318436),\n",
              " ('wife', 0.26091172315990346),\n",
              " ('aragon', 0.25844541581050506),\n",
              " ('monarch', 0.25781944140528035),\n",
              " ('throne', 0.256782835877586),\n",
              " ('son', 0.25424550637754495),\n",
              " ('heir', 0.25296070456687614)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVDhUiMmgfPZ",
        "colab_type": "text"
      },
      "source": [
        "### Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z09uHc1zgfPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clusters = word2vec.load_clusters('/Users/drodriguez/Downloads/text8-clusters.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp7Pd0pIgfPd",
        "colab_type": "text"
      },
      "source": [
        "We can see get the cluster number for individual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iivR8QhdgfPd",
        "colab_type": "code",
        "outputId": "b5397d49-e380-4cc6-df2b-8f2650a60606",
        "colab": {}
      },
      "source": [
        "clusters.vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['</s>', 'the', 'of', ..., 'bredon', 'skirting', 'santamaria'],\n",
              "      dtype='<U29')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oL_g5_LgfPl",
        "colab_type": "text"
      },
      "source": [
        "We can see get all the words grouped on an specific cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFmtdizogfPo",
        "colab_type": "code",
        "outputId": "80cfe5fe-53ce-41f1-b1d8-1d820848efc4",
        "colab": {}
      },
      "source": [
        "clusters.get_words_on_cluster(90).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(206,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIhVgiLHgfPx",
        "colab_type": "code",
        "outputId": "9a094f70-2432-4dee-a264-b8055755c076",
        "colab": {}
      },
      "source": [
        "clusters.get_words_on_cluster(90)[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['along', 'associated', 'relations', 'relationship', 'deal',\n",
              "       'combined', 'contact', 'connection', 'respect', 'mixed'],\n",
              "      dtype='<U29')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AS0jlkLgfP4",
        "colab_type": "text"
      },
      "source": [
        "We can add the clusters to the word2vec model and generate a response that includes the clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62xyOr8OgfP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.clusters = clusters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dEWP8RZgfP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexes, metrics = model.analogy(pos=[\"paris\", \"germany\"], neg=[\"france\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzsJqtvcgfQE",
        "colab_type": "code",
        "outputId": "e4a1c25d-da81-4e8d-a654-0b034e80f9bd",
        "colab": {}
      },
      "source": [
        "model.generate_response(indexes, metrics).tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('berlin', 0.3187078682472152, 15),\n",
              " ('vienna', 0.28562803640143397, 12),\n",
              " ('munich', 0.28527806428082675, 21),\n",
              " ('moscow', 0.27085681100243797, 74),\n",
              " ('leipzig', 0.2697639527846636, 8),\n",
              " ('st_petersburg', 0.25841328545046965, 61),\n",
              " ('prague', 0.2571333430942206, 72),\n",
              " ('bonn', 0.2546126113385251, 8),\n",
              " ('dresden', 0.2471285069069249, 71),\n",
              " ('warsaw', 0.2450778083401204, 74)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VLJes2QgfQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}