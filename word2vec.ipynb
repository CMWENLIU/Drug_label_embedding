{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of word2vec.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "erGHdgJUgfPH",
        "HVDhUiMmgfPZ"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CMWENLIU/Drug_label_embedding/blob/master/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR7AjTKxglcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install --quiet word2vec\n",
        "! pip install --quiet wget"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDQ5YSwk-gMT",
        "colab_type": "code",
        "outputId": "c45ee355-8036-4354-d3a0-238eeb0f3cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import wget\n",
        "import word2vec\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3azPI5vagfKL",
        "colab_type": "text"
      },
      "source": [
        "# word2vec "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch1oi9SDgfKW",
        "colab_type": "text"
      },
      "source": [
        "This notebook is equivalent to `demo-word.sh`, `demo-analogy.sh`, `demo-phrases.sh` and `demo-classes.sh` from Google."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r23HX4sKgfKa",
        "colab_type": "code",
        "outputId": "7b4006b2-f6c2-4007-ce83-b5fe729e7385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "urls = [\"https://raw.githubusercontent.com/CMWENLIU/Drug_label_embedding/master/pubmed/abs1.txt\",\n",
        "       \"https://raw.githubusercontent.com/CMWENLIU/Drug_label_embedding/master/pubmed/abs2.txt\",\n",
        "       ]\n",
        "[wget.download(u) for u in urls]   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abs1 (2).txt', 'abs2 (2).txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQIlfXKgjcZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_str(string):\n",
        "   \n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    string = string.replace(\"\\\\\",\"\")\n",
        "    return string.strip().lower()\n",
        "\n",
        "def split_record(s):\n",
        "  journal = s.split('-!!-', 1)[0]\n",
        "  temp = s.split('-!!-', 1)[1]\n",
        "  year = temp.split('-##-', 1)[0]\n",
        "  abstract = s.split('-##-', 1)[1]\n",
        "  return journal, year, abstract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs9x0KHV97cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with open('w2vdata', 'w') as wf:\n",
        "#  with open('abs2.txt') as f:\n",
        "#    for line in f:\n",
        "#      if '-##-' in line:\n",
        "#        line = clean_str(line.split('-##-', 1)[1])\n",
        "#        wf.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl1ghDNpiZAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "stop_words = set(stopwords.words('english')) \n",
        "with open('w2vdata', 'w') as wf:\n",
        "  with open('TS.txt') as f:\n",
        "    for line in f:\n",
        "        line = clean_str(line)\n",
        "        #line = [w for w in line if not w in stop_words] \n",
        "        wf.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMsyiyECgfKn",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3Pw6toxgfK4",
        "colab_type": "text"
      },
      "source": [
        "Run `word2phrase` to group up similar words \"Los Angeles\" to \"Los_Angeles\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-jLVKWzgfK6",
        "colab_type": "code",
        "outputId": "6998874d-2706-4468-d785-dca72ffa7972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "word2vec.word2phrase('w2vdata', 'w2vdata-phrases', verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training using file w2vdata\n",
            "\n",
            "Vocab size (unigrams + bigrams): 481486\n",
            "Words in train file: 2130459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK12eA7_gfLE",
        "colab_type": "text"
      },
      "source": [
        "This created a `text8-phrases` file that we can use as a better input for `word2vec`.\n",
        "Note that you could easily skip this previous step and use the text data as input for `word2vec` directly.\n",
        "\n",
        "Now actually train the word2vec model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1JqcPAwgfLG",
        "colab_type": "code",
        "outputId": "d0946f6d-1738-4050-8252-6654691bae4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "word2vec.word2vec('w2vdata-phrases', 'w2vdata.bin', size=100, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training using file w2vdata-phrases\n",
            "Vocab size: 25079\n",
            "Words in train file: 1758403\n",
            "Alpha: 0.000002  Progress: 100.42%  Words/thread/sec: 187.17k  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbDXPFk0gfLS",
        "colab_type": "text"
      },
      "source": [
        "That created a `text8.bin` file containing the word vectors in a binary format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVMhRjqjgfLa",
        "colab_type": "text"
      },
      "source": [
        "Now we generate the clusters of the vectors based on the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl0elmE1gfLc",
        "colab_type": "code",
        "outputId": "5ee784d1-c626-476c-b243-0bef85aa0252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "word2vec.word2clusters('w2vdata', 'w2vdata-clusters.txt', 100, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training using file w2vdata\n",
            "Vocab size: 20800\n",
            "Words in train file: 1941197\n",
            "Alpha: 0.000002  Progress: 100.41%  Words/thread/sec: 188.30k  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_FBKaoOgfLn",
        "colab_type": "text"
      },
      "source": [
        "That created a `text8-clusters.txt` with the cluster for every word in the vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV-GEdnAgfLq",
        "colab_type": "text"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy5jgVbIgfLt",
        "colab_type": "code",
        "outputId": "c3203fbc-f922-4775-e0d0-ba7bd62725d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCCdfrLZgfMH",
        "colab_type": "text"
      },
      "source": [
        "Import the `word2vec` binary file created above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h77QQF8_gfMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = word2vec.load('w2vdata.bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjZB01j5gfMO",
        "colab_type": "text"
      },
      "source": [
        "We can take a look at the vocabulary as a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvWh2b0igfMR",
        "colab_type": "code",
        "outputId": "002d2047-e04c-48e5-c371-10ba6db4f1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['</s>', ',', 'of', ..., 'bmo', 'bbo', 'sorbents'], dtype='<U78')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF4A-9Q0gfMi",
        "colab_type": "text"
      },
      "source": [
        "Or take a look at the whole matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA9z9gN1gfMm",
        "colab_type": "code",
        "outputId": "092fcf8a-7f77-4186-db37-dbefcf062eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.vectors.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25079, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsm45nLZgfMy",
        "colab_type": "code",
        "outputId": "35f2df6b-9b7c-4655-9f4c-f4a3318eaf0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "model.vectors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.14333282,  0.15825513, -0.13715845, ...,  0.05456942,\n",
              "         0.10955409,  0.00693387],\n",
              "       [-0.10035713,  0.05325497,  0.06101317, ...,  0.16725662,\n",
              "        -0.0775808 , -0.04770358],\n",
              "       [-0.14344479, -0.0397615 ,  0.11518496, ..., -0.0714288 ,\n",
              "         0.02132738,  0.12340144],\n",
              "       ...,\n",
              "       [-0.1776311 , -0.09941112, -0.14281759, ...,  0.1621709 ,\n",
              "        -0.00876815, -0.07769725],\n",
              "       [-0.09071511, -0.07830397,  0.04456994, ...,  0.13834722,\n",
              "         0.13762638, -0.1301478 ],\n",
              "       [-0.20501305, -0.10979778, -0.00982187, ...,  0.10732359,\n",
              "        -0.06530824, -0.04285794]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NztBBHRbgfND",
        "colab_type": "text"
      },
      "source": [
        "We can retreive the vector of individual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9GmV3-bgfNF",
        "colab_type": "code",
        "outputId": "48be9f09-6cee-4018-c12d-24f69cc211ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model['cell'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAU4Vd3qgfNN",
        "colab_type": "code",
        "outputId": "8758a8d3-a3f8-4929-d138-b895e9f925b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model['cell'][:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.02201957,  0.13889974,  0.01483452, -0.14323322, -0.02133687,\n",
              "        0.03510084, -0.10194293,  0.08460193, -0.03827839, -0.06916734])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abCeT_w3gfNe",
        "colab_type": "text"
      },
      "source": [
        "We can calculate the distance between two or more (all combinations) words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDLt4t7hgfNn",
        "colab_type": "code",
        "outputId": "ff8a1221-b172-4c1f-a773-edd645829083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "model.distance(\"egg\", \"protein\", \"gluten\", \"tumor\",\"cancer\", \"disease\", \"analytic\", \"scientific\", \"diagnostic\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-39ec04f4c6bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"egg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"protein\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gluten\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tumor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"cancer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"disease\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"analytic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scientific\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"diagnostic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/word2vec/wordvectors.py\u001b[0m in \u001b[0;36mdistance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/word2vec/wordvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/word2vec/wordvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"\"\"\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/word2vec/wordvectors.py\u001b[0m in \u001b[0;36mix\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mon\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \"\"\"\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_hash\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'analytic'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcT2BVvAgfNz",
        "colab_type": "text"
      },
      "source": [
        "## Similarity\n",
        "\n",
        "We can do simple queries to retreive words similar to \"socks\" based on cosine similarity:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7eHXaEWgfN0",
        "colab_type": "code",
        "outputId": "c07df3a5-2a01-4169-ee54-db289b708a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "indexes, metrics = model.similar(\"cell\")\n",
        "indexes, metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  306,   591,   480,   880, 13796,   983,   602,    33,   711,\n",
              "         1156]),\n",
              " array([0.75267106, 0.74565173, 0.74452586, 0.73334029, 0.70504718,\n",
              "        0.70163644, 0.70144433, 0.69382283, 0.68474115, 0.68359934]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8KVq_dbgfN_",
        "colab_type": "text"
      },
      "source": [
        "This returned a tuple with 2 items:\n",
        "1. numpy array with the indexes of the similar words in the vocabulary\n",
        "2. numpy array with cosine similarity to each word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9bHxJcZgfOD",
        "colab_type": "text"
      },
      "source": [
        "We can get the words for those indexes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATm-dUMLgfOF",
        "colab_type": "code",
        "outputId": "0fb66b7b-e29b-4f1e-d648-4044fac3621f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.vocab[indexes]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['primary', 'epithelial', 'derived', 'murine', 'cd4_kj',\n",
              "       'hepatocyte', 'cell_line', 'cells', 'cultures', 'bone_marrow'],\n",
              "      dtype='<U78')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GRWsL91gfOa",
        "colab_type": "text"
      },
      "source": [
        "There is a helper function to create a combined response as a numpy [record array](http://docs.scipy.org/doc/numpy/user/basics.rec.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CySBuJuQgfOb",
        "colab_type": "code",
        "outputId": "7465bf2c-4370-4491-c62d-28fea35925f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "model.generate_response(indexes, metrics)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rec.array([('animal', 0.94223076), ('experimental', 0.8944898 ),\n",
              "           ('preclinical', 0.87991323), ('toxicogenomics', 0.85871615),\n",
              "           ('toxicologyresearch', 0.85729209), ('food', 0.85487465),\n",
              "           ('epidemiology', 0.83767078), ('environmentaland', 0.83595806),\n",
              "           ('toxic_substances', 0.83162512), ('industrial', 0.82925473)],\n",
              "          dtype=[('word', '<U78'), ('metric', '<f8')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxK8TqHIgfOl",
        "colab_type": "text"
      },
      "source": [
        "Is easy to make that numpy array a pure python response:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWyT8PujgfOr",
        "colab_type": "code",
        "outputId": "a7526164-d317-4c30-febf-111da4d6aaf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "model.generate_response(indexes, metrics).tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('animal', 0.9422307571217683),\n",
              " ('experimental', 0.8944898013342577),\n",
              " ('preclinical', 0.879913234534419),\n",
              " ('toxicogenomics', 0.8587161536414003),\n",
              " ('toxicologyresearch', 0.8572920856200303),\n",
              " ('food', 0.8548746496140631),\n",
              " ('epidemiology', 0.8376707770763547),\n",
              " ('environmentaland', 0.8359580588585981),\n",
              " ('toxic_substances', 0.831625124038414),\n",
              " ('industrial', 0.829254732607843)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TozeeGcEgfO0",
        "colab_type": "text"
      },
      "source": [
        "### Phrases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDFRuC6PgfO2",
        "colab_type": "text"
      },
      "source": [
        "Since we trained the model with the output of `word2phrase` we can ask for similarity of \"phrases\", basically compained words such as \"Los Angeles\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuniNouigfO3",
        "colab_type": "code",
        "outputId": "40764599-18c2-4e9f-ecac-baa80f73e922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "indexes, metrics = model.similar('cell')\n",
        "model.generate_response(indexes, metrics).tolist()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('primary', 0.75267106249543),\n",
              " ('epithelial', 0.7456517271791423),\n",
              " ('derived', 0.7445258619401021),\n",
              " ('murine', 0.7333402941904732),\n",
              " ('cd4_kj', 0.7050471750765015),\n",
              " ('hepatocyte', 0.701636436826913),\n",
              " ('cell_line', 0.701444331042083),\n",
              " ('cells', 0.69382283358038),\n",
              " ('cultures', 0.6847411456441168),\n",
              " ('bone_marrow', 0.6835993449894815)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erGHdgJUgfPH",
        "colab_type": "text"
      },
      "source": [
        "### Analogies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDlCYBIagfPI",
        "colab_type": "text"
      },
      "source": [
        "Its possible to do more complex queries like analogies such as: `king - man + woman = queen` \n",
        "This method returns the same as `cosine` the indexes of the words in the vocab and the metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHOGGqmSgfPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexes, metrics = model.analogy(pos=['king', 'woman'], neg=['man'])\n",
        "indexes, metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdtmMnUdgfPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.generate_response(indexes, metrics).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVDhUiMmgfPZ",
        "colab_type": "text"
      },
      "source": [
        "### Clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z09uHc1zgfPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clusters = word2vec.load_clusters('/Users/drodriguez/Downloads/text8-clusters.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp7Pd0pIgfPd",
        "colab_type": "text"
      },
      "source": [
        "We can see get the cluster number for individual words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iivR8QhdgfPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clusters.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oL_g5_LgfPl",
        "colab_type": "text"
      },
      "source": [
        "We can see get all the words grouped on an specific cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFmtdizogfPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clusters.get_words_on_cluster(90).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIhVgiLHgfPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clusters.get_words_on_cluster(90)[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AS0jlkLgfP4",
        "colab_type": "text"
      },
      "source": [
        "We can add the clusters to the word2vec model and generate a response that includes the clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62xyOr8OgfP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.clusters = clusters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dEWP8RZgfP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexes, metrics = model.analogy(pos=[\"paris\", \"germany\"], neg=[\"france\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzsJqtvcgfQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.generate_response(indexes, metrics).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VLJes2QgfQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}